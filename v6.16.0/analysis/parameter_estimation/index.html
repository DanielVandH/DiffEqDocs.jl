<!DOCTYPE html><HTML lang="en"><head><meta charset="UTF-8"/><meta content="width=device-width, initial-scale=1.0" name="viewport"/><title>Parameter Estimation and Bayesian Analysis Â· DifferentialEquations.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-90474609-3', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://diffeq.sciml.ai/stable/analysis/parameter_estimation/" rel="canonical"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script data-main="../../assets/documenter.js" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" data-theme-name="documenter-dark" href="../../assets/themes/documenter-dark.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" data-theme-name="documenter-light" data-theme-primary="" href="../../assets/themes/documenter-light.css" rel="stylesheet" type="text/css"/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><script data-is-old-version="">document.addEventListener("DOMContentLoaded", function(){
    const div = document.createElement('div');
    div.setAttribute('style', 'position: fixed; bottom: 1em; right: 1em; z-index: 999; background-color: #ffaf9c; color: rgba(0, 0, 0, 0.7); border: 1px solid #d54625; border-radius: 4px; padding: 2em; text-align: center');
    const closer = document.createElement('div');
    closer.setAttribute('style', 'position: absolute; top: 0; right: 5px; padding: 5px; cursor: pointer; width: 12px; height: 12px;')
    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', () => {
        document.body.removeChild(div)
    })
    const href = documenterBaseURL + '/../stable'
    div.innerHTML = 'This is an old version of the documentation. <br> Click <a href="' + href + '">here</a> to go to the newest version.';
    div.appendChild(closer)
    document.body.appendChild(div);
});
</script><script data-outdated-warner="">function maybeAddWarning () {
    const head = document.getElementsByTagName('head')[0];

    // Add a noindex meta tag (unless one exists) so that search engines don't index this version of the docs.
    if (document.body.querySelector('meta[name="robots"]') === null) {
        const meta = document.createElement('meta');
        meta.name = 'robots';
        meta.content = 'noindex';

        head.appendChild(meta);
    };

    // Add a stylesheet to avoid inline styling
    const style = document.createElement('style');
    style.type = 'text/css';
    style.appendChild(document.createTextNode('.outdated-warning-overlay {  position: fixed;  top: 0;  left: 0;  right: 0;  box-shadow: 0 0 10px rgba(0, 0, 0, 0.3);  z-index: 999;  background-color: #ffaba7;  color: rgba(0, 0, 0, 0.7);  border-bottom: 3px solid #da0b00;  padding: 10px 35px;  text-align: center;  font-size: 15px; }  .outdated-warning-overlay .outdated-warning-closer {    position: absolute;    top: calc(50% - 10px);    right: 18px;    cursor: pointer;    width: 12px; }  .outdated-warning-overlay a {    color: #2e63b8; }    .outdated-warning-overlay a:hover {      color: #363636; }'));
    head.appendChild(style);

    const div = document.createElement('div');
    div.classList.add('outdated-warning-overlay');
    const closer = document.createElement('div');
    closer.classList.add('outdated-warning-closer');

    // Icon by font-awesome (license: https://fontawesome.com/license, link: https://fontawesome.com/icons/times?style=solid)
    closer.innerHTML = '<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="times" class="svg-inline--fa fa-times fa-w-11" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 352 512"><path fill="currentColor" d="M242.72 256l100.07-100.07c12.28-12.28 12.28-32.19 0-44.48l-22.24-22.24c-12.28-12.28-32.19-12.28-44.48 0L176 189.28 75.93 89.21c-12.28-12.28-32.19-12.28-44.48 0L9.21 111.45c-12.28 12.28-12.28 32.19 0 44.48L109.28 256 9.21 356.07c-12.28 12.28-12.28 32.19 0 44.48l22.24 22.24c12.28 12.28 32.2 12.28 44.48 0L176 322.72l100.07 100.07c12.28 12.28 32.2 12.28 44.48 0l22.24-22.24c12.28-12.28 12.28-32.19 0-44.48L242.72 256z"></path></svg>';
    closer.addEventListener('click', function () {
        document.body.removeChild(div);
    });
    let href = '/stable';
    if (window.documenterBaseURL) {
        href = window.documenterBaseURL + '/../stable';
    }
    div.innerHTML = 'This is an old version of the documentation. <br> <a href="' + href + '">Go to the newest version</a>.';
    div.appendChild(closer);
    document.body.appendChild(div);
};

if (document.readyState === 'loading') {
    document.addEventListener('DOMContentLoaded', maybeAddWarning);
} else {
    maybeAddWarning();
};
</script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img alt="DifferentialEquations.jl logo" src="../../assets/logo.png"/></a><div class="docs-package-name"><span class="docs-autofit">DifferentialEquations.jl</span></div><form action="../../search/" class="docs-search"><input class="docs-search-query" id="documenter-search-query" name="q" placeholder="Search docs" type="text"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">DifferentialEquations.jl: Scientific Machine Learning (SciML) Enabled Simulation and Estimation</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/ode_example/">Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/advanced_ode_example/">Solving Stiff Equations</a></li><li><a class="tocitem" href="../../tutorials/sde_example/">Stochastic Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/rode_example/">Random Ordinary Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/dde_example/">Delay Differential Equations</a></li><li><a class="tocitem" href="../../tutorials/dae_example/">Differential Algebraic Equations</a></li><li><a class="tocitem" href="../../tutorials/discrete_stochastic_example/">Discrete Stochastic (Gillespie) Equations</a></li><li><a class="tocitem" href="../../tutorials/jump_diffusion/">Jump Diffusion Equations</a></li><li><a class="tocitem" href="../../tutorials/bvp_example/">Boundary Value Problems</a></li><li><a class="tocitem" href="../../tutorials/additional/">Additional Tutorials</a></li></ul></li><li><span class="tocitem">Basics</span><ul><li><a class="tocitem" href="../../basics/overview/">Overview of DifferentialEquations.jl</a></li><li><a class="tocitem" href="../../basics/common_solver_opts/">Common Solver Options</a></li><li><a class="tocitem" href="../../basics/solution/">Solution Handling</a></li><li><a class="tocitem" href="../../basics/plot/">Plot Functions</a></li><li><a class="tocitem" href="../../basics/integrator/">Integrator Interface</a></li><li><a class="tocitem" href="../../basics/problem/">Problem Interface</a></li><li><a class="tocitem" href="../../basics/faq/">Frequently Asked Questions</a></li><li><a class="tocitem" href="../../basics/compatibility_chart/">Solver Compatibility Chart</a></li></ul></li><li><span class="tocitem">Problem Types</span><ul><li><a class="tocitem" href="../../types/discrete_types/">Discrete Problems</a></li><li><a class="tocitem" href="../../types/ode_types/">ODE Problems</a></li><li><a class="tocitem" href="../../types/nonautonomous_linear_ode/">Non-autonomous Linear ODE / Lie Group Problems</a></li><li><a class="tocitem" href="../../types/dynamical_types/">Dynamical, Hamiltonian and 2nd Order ODE Problems</a></li><li><a class="tocitem" href="../../types/split_ode_types/">Split ODE Problems</a></li><li><a class="tocitem" href="../../types/steady_state_types/">Steady State Problems</a></li><li><a class="tocitem" href="../../types/bvp_types/">BVP Problems</a></li><li><a class="tocitem" href="../../types/sde_types/">SDE Problems</a></li><li><a class="tocitem" href="../../types/rode_types/">RODE Problems</a></li><li><a class="tocitem" href="../../types/dde_types/">DDE Problems</a></li><li><a class="tocitem" href="../../types/sdde_types/">SDDE Problems</a></li><li><a class="tocitem" href="../../types/dae_types/">DAE Problems</a></li><li><a class="tocitem" href="../../types/jump_types/">Jump Problems</a></li></ul></li><li><span class="tocitem">Solver Algorithms</span><ul><li><a class="tocitem" href="../../solvers/discrete_solve/">Discrete Solvers</a></li><li><a class="tocitem" href="../../solvers/ode_solve/">ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/nonautonomous_linear_ode/">Non-autonomous Linear ODE / Lie Group ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/dynamical_solve/">Dynamical, Hamiltonian, and 2nd Order ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/split_ode_solve/">Split ODE Solvers</a></li><li><a class="tocitem" href="../../solvers/steady_state_solve/">Steady State Solvers</a></li><li><a class="tocitem" href="../../solvers/bvp_solve/">BVP Solvers</a></li><li><a class="tocitem" href="../../solvers/jump_solve/">Jump Problem and Jump Diffusion Solvers</a></li><li><a class="tocitem" href="../../solvers/sde_solve/">SDE Solvers</a></li><li><a class="tocitem" href="../../solvers/rode_solve/">RODE Solvers</a></li><li><a class="tocitem" href="../../solvers/dde_solve/">SDDE Solvers</a></li><li><a class="tocitem" href="../../solvers/sdde_solve/">SDDE Solvers</a></li><li><a class="tocitem" href="../../solvers/dae_solve/">DAE Solvers</a></li><li><a class="tocitem" href="../../solvers/benchmarks/">Solver Benchmarks</a></li></ul></li><li><span class="tocitem">Additional Features</span><ul><li><a class="tocitem" href="../../features/performance_overloads/">DiffEqFunctions (Jacobians, Gradients, etc.) and Jacobian Types</a></li><li><a class="tocitem" href="../../features/diffeq_arrays/">DiffEq-Specific Array Types</a></li><li><a class="tocitem" href="../../features/diffeq_operator/">DiffEqOperators</a></li><li><a class="tocitem" href="../../features/noise_process/">Noise Processes</a></li><li><a class="tocitem" href="../../features/linear_nonlinear/">Specifying (Non)Linear Solvers</a></li><li><a class="tocitem" href="../../features/callback_functions/">Event Handling and Callback Functions</a></li><li><a class="tocitem" href="../../features/callback_library/">Callback Library</a></li><li><a class="tocitem" href="../../features/ensemble/">Parallel Ensemble Simulations</a></li><li><a class="tocitem" href="../../features/io/">I/O: Saving and Loading Solution Data</a></li><li><a class="tocitem" href="../../features/low_dep/">Low Dependency Usage</a></li><li><a class="tocitem" href="../../features/progress_bar/">Progress Bar Integration</a></li></ul></li><li><span class="tocitem">Analysis Tools</span><ul><li><a class="tocitem" href="../parameterized_functions/">ParameterizedFunctions</a></li><li class="is-active"><a class="tocitem" href="">Parameter Estimation and Bayesian Analysis</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Recommended-Methods"><span>Recommended Methods</span></a></li><li><a class="tocitem" href="#Optimization-Based-Methods"><span>Optimization-Based Methods</span></a></li><li><a class="tocitem" href="#Bayesian-Methods"><span>Bayesian Methods</span></a></li><li><a class="tocitem" href="#Optimization-Based-ODE-Inference-Examples"><span>Optimization-Based ODE Inference Examples</span></a></li><li><a class="tocitem" href="#Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles"><span>Parameter Estimation for Stochastic Differential Equations and Ensembles</span></a></li><li><a class="tocitem" href="#Bayesian-Inference-Examples"><span>Bayesian Inference Examples</span></a></li></ul></li><li><a class="tocitem" href="../bifurcation/">Bifurcation Analysis</a></li><li><a class="tocitem" href="../sensitivity/">Local Sensitivity Analysis (Automatic Differentiation)</a></li><li><a class="tocitem" href="../global_sensitivity/">Global Sensitivity Analysis</a></li><li><a class="tocitem" href="../uncertainty_quantification/">Uncertainty Quantification</a></li><li><a class="tocitem" href="../neural_networks/">Neural Networks</a></li><li><a class="tocitem" href="../dev_and_test/">Algorithm Development and Testing</a></li></ul></li><li><span class="tocitem">Domain Modeling Tools</span><ul><li><a class="tocitem" href="../../models/multiscale/">Multi-Scale Models</a></li><li><a class="tocitem" href="../../models/physical/">Physical Models</a></li><li><a class="tocitem" href="../../models/financial/">Financial Models</a></li><li><a class="tocitem" href="../../models/chemical_reactions/">Chemical Reactions</a></li><li><a class="tocitem" href="../../models/external_modeling/">External Modeling Packages</a></li></ul></li><li><span class="tocitem">Extra Details</span><ul><li><a class="tocitem" href="../../extras/timestepping/">Timestepping Method Descriptions</a></li><li><a class="tocitem" href="../../extras/sensitivity_math/">Mathematics of Sensitivity Analysis</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Analysis Tools</a></li><li class="is-active"><a href="">Parameter Estimation and Bayesian Analysis</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="">Parameter Estimation and Bayesian Analysis</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DiffEqDocs.jl/blob/master/docs/src/analysis/parameter_estimation.md" title="Edit on GitHub"><span class="docs-icon fab">ï</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" href="#" id="documenter-settings-button" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" href="#" id="documenter-sidebar-button"></a></div></header><article class="content" id="documenter-page"><h1 id="parameter_estimation"><a class="docs-heading-anchor" href="#parameter_estimation">Parameter Estimation and Bayesian Analysis</a><a id="parameter_estimation-1"></a><a class="docs-heading-anchor-permalink" href="#parameter_estimation" title="Permalink"></a></h1><p>Parameter estimation for differential equation models, also known as dynamic data analysis, is provided by the DiffEq suite.</p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>This functionality does not come standard with DifferentialEquations.jl. To use this functionality, you must install DiffEqParamEstim.jl:</p><pre><code class="language-julia">]add DiffEqParamEstim
using DiffEqParamEstim</code></pre><p>For the Bayesian, methods, you must install DiffEqBayes.jl:</p><pre><code class="language-julia">]add DiffEqBayes
using DiffEqBayes</code></pre><h2 id="Recommended-Methods"><a class="docs-heading-anchor" href="#Recommended-Methods">Recommended Methods</a><a id="Recommended-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Recommended-Methods" title="Permalink"></a></h2><p>The recommended method is to use <code>build_loss_objective</code> with the optimizer of your choice. This method can thus be paired with global optimizers from packages like BlackBoxOptim.jl or NLopt.jl which can be much less prone to finding local minima than local optimization methods. Also, it allows the user to define the cost function in the way they choose as a function <code>loss(sol)</code>, and thus can fit using any cost function on the solution, making it applicable to fitting non-temporal data and other types of problems. Also, <code>build_loss_objective</code> works for all of the <code>DEProblem</code> types, allowing it to optimize parameters on ODEs, SDEs, DDEs, DAEs, etc.</p><p>However, this method requires repeated solution of the differential equation. If the data is temporal data, the most efficient method is the <code>two_stage_method</code> which does not require repeated solutions but is not as accurate. Usage of the <code>two_stage_method</code> should have a post-processing step which refines using a method like <code>build_loss_objective</code>.</p><h2 id="Optimization-Based-Methods"><a class="docs-heading-anchor" href="#Optimization-Based-Methods">Optimization-Based Methods</a><a id="Optimization-Based-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-Based-Methods" title="Permalink"></a></h2><h3 id="Nonlinear-Regression"><a class="docs-heading-anchor" href="#Nonlinear-Regression">Nonlinear Regression</a><a id="Nonlinear-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-Regression" title="Permalink"></a></h3><p><code>build_loss_objective</code> builds an objective function to be used with Optim.jl and MathProgBase-associated solvers like NLopt.</p><pre><code class="language-julia">function build_loss_objective(prob::DEProblem,alg,loss_func
                              regularization=nothing;
                              mpg_autodiff = false,
                              verbose_opt = false,
                              verbose_steps = 100,
                              prob_generator = (prob,p)-&gt;remake(prob,p=p),
                              kwargs...)</code></pre><p>The first argument is the <code>DEProblem</code> to solve, and next is the <code>alg</code> to use. The <code>alg</code> must match the problem type, which can be any <code>DEProblem</code> (ODEs, SDEs, DAEs, DDEs, etc.). <code>regularization</code> defaults to nothing which has no regularization function. One can also choose <code>verbose_opt</code> and <code>verbose_steps</code>, which, in the optimization routines, will print the steps and the values at the steps every <code>verbose_steps</code> steps. <code>mpg_autodiff</code> uses autodifferentiation to define the derivative for the MathProgBase solver. The extra keyword arguments are passed to the differential equation solver.</p><h3 id="Multiple-Shooting-objective"><a class="docs-heading-anchor" href="#Multiple-Shooting-objective">Multiple Shooting objective</a><a id="Multiple-Shooting-objective-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-Shooting-objective" title="Permalink"></a></h3><p>Multiple Shooting is generally used in Boundary Value Problems (BVP) and is more robust than the regular objective function used in these problems. It proceeds as follows:</p><ul><li>Divide up the time span into short time periods and solve the equation with the current parameters which here consist of both, the parameters of the differential equations and also the initial values for the short time periods.</li><li>This objective additionally involves a discontinuity error term that imposes higher cost if the end of the solution of one time period doesn't match the beginning of the next one.</li><li>Merge the solutions from the shorter intervals and then calculate the loss.</li></ul><pre><code class="language-julia">function multiple_shooting_objective(prob::DiffEqBase.DEProblem,alg,loss,
                              regularization=nothing;prior=nothing,
                              mpg_autodiff = false,discontinuity_weight=1.0,
                              verbose_opt = false,
                              prob_generator = STANDARD_PROB_GENERATOR,
                              autodiff_prototype = mpg_autodiff ? zeros(init_N_params) : nothing,
                              autodiff_chunk = mpg_autodiff ? ForwardDiff.Chunk(autodiff_prototype) : nothing,
                              kwargs...)</code></pre><p>For consistency <code>multiple_shooting_objective</code> takes exactly the same arguments as <code>build_loss_objective</code>. It also has the option for <code>discontinuity_error</code> as a keyword argument which assigns weight to the error occurring due to the discontinuity that arises from the breaking up of the time span.</p><h3 id="Two-Stage-method-(Non-Parametric-Collocation)"><a class="docs-heading-anchor" href="#Two-Stage-method-(Non-Parametric-Collocation)">Two Stage method (Non-Parametric Collocation)</a><a id="Two-Stage-method-(Non-Parametric-Collocation)-1"></a><a class="docs-heading-anchor-permalink" href="#Two-Stage-method-(Non-Parametric-Collocation)" title="Permalink"></a></h3><p>The two-stage method is a collocation method for estimating parameters without requiring repeated solving of the differential equation. It does so by determining a smoothed estimated trajectory of the data (local quadratic polynomial fit by least squares) and optimizing the derivative function and the data's timepoints to match the derivatives of the smoothed trajectory. This method has less accuracy than other methods but is much faster, and is a good method to try first to get in the general "good parameter" region, to then finish using one of the other methods.</p><pre><code class="language-julia">function two_stage_method(prob::DEProblem,tpoints,data;kernel= :Epanechnikov,
                          loss_func = L2DistLoss,mpg_autodiff = false,
                          verbose = false,verbose_steps = 100)</code></pre><h4 id="The-Loss-Function"><a class="docs-heading-anchor" href="#The-Loss-Function">The Loss Function</a><a id="The-Loss-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Loss-Function" title="Permalink"></a></h4><pre><code class="language-julia">loss_func(sol)</code></pre><p>is a function which reduces the problem's solution to a scalar which the optimizer will try to minimize. While this is very flexible, two convenience routines are included for fitting to data with standard cost functions:</p><pre><code class="language-julia">L2Loss(t,data;differ_weight=nothing,data_weight=nothing,
              colloc_grad=nothing,dudt=nothing)</code></pre><p>where <code>t</code> is the set of timepoints which the data is found at, and <code>data</code> are the values that are known where each column corresponds to measures of the values of the system. <code>L2Loss</code> is an optimized version of the L2-distance. The <code>data_weight</code> is a scalar or vector of weights for the loss function which must match the size of the data. Note that minimization of a weighted <code>L2Loss</code> is equivalent to maximum likelihood estimation of a heteroskedastic Normally distributed likelihood. <code>differ_weight</code> allows one to add a weight on the first differencing terms <code>sol[i+1]-sol[i]</code> against the data first differences. This smooths out the loss term and can make it easier to fit strong solutions of stochastic models, but is zero (nothing) by default. Additionally, <code>colloc_grad</code> allows one to give a matrix of the collocation gradients for the data. This is used to add an interpolation derivative term, like the two-stage method. A convenience function <code>colloc_grad(t,data)</code> returns a collocation gradient from a 3rd order spline calculated by Dierckx.jl, which can be used as the <code>colloc_grad</code>. Note that, with a collocation gradient and regularization, this loss is equivalent to a 4DVAR.</p><p>Additionally, we include a more flexible log-likelihood approach:</p><pre><code class="language-julia">LogLikeLoss(t,distributions,diff_distributions=nothing)</code></pre><p>In this case, there are two forms. The simple case is where <code>distributions[i,j]</code> is the likelihood distributions from a <code>UnivariateDistribution</code> from <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a>, where it corresponds to the likelihood at <code>t[i]</code> for component <code>j</code>. The second case is where <code>distributions[i]</code> is a <code>MultivariateDistribution</code> which corresponds to the likelihood at <code>t[i]</code> over the vector of components. This likelihood function then calculates the negative of the total loglikelihood over time as its objective value (negative since optimizers generally find minimums, and thus this corresponds to maximum likelihood estimation). The third term, <code>diff_distributions</code>, acts similarly but allows putting a distribution on the first difference terms <code>sol[i+1]-sol[i]</code>.</p><p>Note that these distributions can be generated via <code>fit_mle</code> on some dataset against some chosen distribution type.</p><h4 id="Note-About-Loss-Functions"><a class="docs-heading-anchor" href="#Note-About-Loss-Functions">Note About Loss Functions</a><a id="Note-About-Loss-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Note-About-Loss-Functions" title="Permalink"></a></h4><p>For parameter estimation problems, it's not uncommon for the optimizers to hit unstable regions of parameter space. This causes warnings that the solver exited early, and the built-in loss functions like <code>L2Loss</code> automatically handle this. However, if using a user-supplied loss function, you should make sure it's robust to these issues. One common pattern is to apply infinite loss when the integration is not successful. Using the retcodes, this can be done via:</p><pre><code class="language-julia">function my_loss_function(sol)
   tot_loss = 0.0
   if any((s.retcode != :Success for s in sol))
     tot_loss = Inf
   else
     # calculation for the loss here
   end
   tot_loss
end</code></pre><h4 id="Note-on-First-Differencing"><a class="docs-heading-anchor" href="#Note-on-First-Differencing">Note on First Differencing</a><a id="Note-on-First-Differencing-1"></a><a class="docs-heading-anchor-permalink" href="#Note-on-First-Differencing" title="Permalink"></a></h4><pre><code class="language-julia">L2Loss(t,data,differ_weight=0.3,data_weight=0.7)</code></pre><p>First differencing incorporates the differences of data points at consecutive time points which adds more information about the trajectory in the loss function. Adding first differencing is helpful in cases where the <code>L2Loss</code> alone leads to non-identifiable parameters but adding a first differencing term makes it more identifiable. This can be noted on stochastic differential equation models, where this aims to capture the autocorrelation and therefore helps us avoid getting the same stationary distribution despite different trajectories and thus wrong parameter estimates.</p><h4 id="The-Regularization-Function"><a class="docs-heading-anchor" href="#The-Regularization-Function">The Regularization Function</a><a id="The-Regularization-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Regularization-Function" title="Permalink"></a></h4><p>The regularization can be any function of <code>p</code>, the parameter vector:</p><pre><code class="language-julia">regularization(p)</code></pre><p>The <code>Regularization</code> helper function builds a regularization using a penalty function <code>penalty</code> from <a href="https://github.com/JuliaML/PenaltyFunctions.jl">PenaltyFunctions.jl</a>:</p><pre><code class="language-julia">Regularization(Î»,penalty=L2Penalty())</code></pre><p>The regularization defaults to L2 if no penalty function is specified. <code>Î»</code> is the weight parameter for the addition of the regularization term.</p><h4 id="The-Problem-Generator-Function"><a class="docs-heading-anchor" href="#The-Problem-Generator-Function">The Problem Generator Function</a><a id="The-Problem-Generator-Function-1"></a><a class="docs-heading-anchor-permalink" href="#The-Problem-Generator-Function" title="Permalink"></a></h4><p>The argument <code>prob_generator</code> allows one to specify a function for generating new problems from a given parameter set. By default, this just builds a new problem which fixes the element types in a way that's autodifferentiation compatible and adds the new parameter vector <code>p</code>. For example, the code for this is:</p><pre><code class="language-julia">prob_generator = (prob,p) -&gt; remake(prob,u0=convert.(eltype(p),prob.u0),p=p)</code></pre><p>Then the new problem with these new values is returned.</p><p>One can use this to change the meaning of the parameters using this function. For example, if one instead wanted to optimize the initial conditions for a function without parameters, you could change this to:</p><pre><code class="language-julia">prob_generator = (prob,p) -&gt; remake(prob.f,u0=p)</code></pre><p>which simply uses <code>p</code> as the initial condition in the initial value problem.</p><h3 id="LeastSquaresOptim.jl-objective"><a class="docs-heading-anchor" href="#LeastSquaresOptim.jl-objective">LeastSquaresOptim.jl objective</a><a id="LeastSquaresOptim.jl-objective-1"></a><a class="docs-heading-anchor-permalink" href="#LeastSquaresOptim.jl-objective" title="Permalink"></a></h3><p><code>build_lsoptim_objective</code> builds an objective function to be used with LeastSquaresOptim.jl.</p><pre><code class="language-julia">build_lsoptim_objective(prob,tspan,t,data;
                        prob_generator = (prob,p) -&gt; remake(prob,u0=convert.(eltype(p),prob.u0),p=p),
                        kwargs...)</code></pre><p>The arguments are the same as <code>build_loss_objective</code>.</p><h3 id="lm_fit"><a class="docs-heading-anchor" href="#lm_fit">lm_fit</a><a id="lm_fit-1"></a><a class="docs-heading-anchor-permalink" href="#lm_fit" title="Permalink"></a></h3><p><code>lm_fit</code> is a function for fitting the parameters of an ODE using the Levenberg-Marquardt algorithm. This algorithm is really bad and thus not recommended since, for example, the Optim.jl algorithms on an L2 loss are more performant and robust. However, this is provided for completeness as most other differential equation libraries use an LM-based algorithm, so this allows one to test the increased effectiveness of not using LM.</p><pre><code class="language-julia">lm_fit(prob::DEProblem,tspan,t,data,p0;
       prob_generator = (prob,p) -&gt; remake(prob,u0=convert.(eltype(p),prob.u0),p=p),
       kwargs...)</code></pre><p>The arguments are similar to before, but with <code>p0</code> being the initial conditions for the parameters and the <code>kwargs</code> as the args passed to the LsqFit <code>curve_fit</code> function (which is used for the LM solver). This returns the fitted parameters.</p><h3 id="MAP-estimate"><a class="docs-heading-anchor" href="#MAP-estimate">MAP estimate</a><a id="MAP-estimate-1"></a><a class="docs-heading-anchor-permalink" href="#MAP-estimate" title="Permalink"></a></h3><p>You can also add a prior option to <code>build_loss_objective</code> and <code>multiple_shooting_objective</code> that essentially turns it into MAP by multiplying the loglikelihood (the cost) by the prior. The option was added as a keyword argument <code>priors</code>, it can take in either an array of univariate distributions for each of the parameters or a multivariate distribution.</p><pre><code class="language-julia">ms_obj = multiple_shooting_objective(ms_prob,Tsit5(),L2Loss(t,data);priors=priors,discontinuity_weight=1.0,abstol=1e-12,reltol=1e-12)</code></pre><h2 id="Bayesian-Methods"><a class="docs-heading-anchor" href="#Bayesian-Methods">Bayesian Methods</a><a id="Bayesian-Methods-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Methods" title="Permalink"></a></h2><p>The following methods require the DiffEqBayes.jl</p><pre><code class="language-julia">]add DiffEqBayes
using DiffEqBayes</code></pre><h3 id="stan_inference"><a class="docs-heading-anchor" href="#stan_inference">stan_inference</a><a id="stan_inference-1"></a><a class="docs-heading-anchor-permalink" href="#stan_inference" title="Permalink"></a></h3><pre><code class="language-julia">stan_inference(prob::ODEProblem,t,data,priors = nothing;alg=:rk45,
               num_samples=1000, num_warmup=1000, reltol=1e-3,
               abstol=1e-6, maxiter=Int(1e5),likelihood=Normal,
               vars=(StanODEData(),InverseGamma(2,3)))</code></pre><p><code>stan_inference</code> uses <a href="https://stanjulia.github.io/CmdStan.jl/latest/INTRO/">Stan.jl</a> to perform the Bayesian inference. The <a href="https://stanjulia.github.io/CmdStan.jl/latest/INSTALLATION/">Stan installation process</a> is required to use this function. <code>t</code> is the array of time and <code>data</code> is the array where the first dimension (columns) corresponds to the array of system values. <code>priors</code> is an array of prior distributions for each parameter, specified via a <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a> type. <code>alg</code> is a choice between <code>:rk45</code> and <code>:bdf</code>, the two internal integrators of Stan. <code>num_samples</code> is the number of samples to take per chain, and <code>num_warmup</code> is the number of MCMC warmup steps. <code>abstol</code> and <code>reltol</code> are the keyword arguments for the internal integrator. <code>likelihood</code> is the likelihood distribution to use with the arguments from <code>vars</code>, and <code>vars</code> is a tuple of priors for the distributions of the likelihood hyperparameters. The special value <code>StanODEData()</code> in this tuple denotes the position that the ODE solution takes in the likelihood's parameter list.</p><h3 id="turing_inference"><a class="docs-heading-anchor" href="#turing_inference">turing_inference</a><a id="turing_inference-1"></a><a class="docs-heading-anchor-permalink" href="#turing_inference" title="Permalink"></a></h3><pre><code class="language-julia">function turing_inference(prob::DiffEqBase.DEProblem,alg,t,data,priors;
                              likelihood_dist_priors, likelihood, num_samples=1000,
                              sampler = Turing.NUTS(num_samples, 0.65), syms, kwargs...)</code></pre><p><code>turing_inference</code> uses <a href="https://github.com/TuringLang/Turing.jl">Turing.jl</a> to perform its parameter inference. <code>prob</code> can be any <code>DEProblem</code> with a corresponding <code>alg</code> choice. <code>t</code> is the array of time points and <code>data</code> is the set of observations for the differential equation system at time point <code>t[i]</code> (or higher dimensional). <code>priors</code> is an array of prior distributions for each parameter, specified via a <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a> type. <code>num_samples</code> is the number of samples per MCMC chain. The extra <code>kwargs</code> are given to the internal differential equation solver.</p><h3 id="dynamichmc_inference"><a class="docs-heading-anchor" href="#dynamichmc_inference">dynamichmc_inference</a><a id="dynamichmc_inference-1"></a><a class="docs-heading-anchor-permalink" href="#dynamichmc_inference" title="Permalink"></a></h3><pre><code class="language-julia">dynamichmc_inference(prob::DEProblem,alg,t,data,priors,transformations;
                      Ï = 0.01,Ïµ=0.001,initial=Float64[])</code></pre><p><code>dynamichmc_inference</code> uses <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a> to  perform the bayesian parameter estimation. <code>prob</code> can be any <code>DEProblem</code>, <code>data</code> is the set  of observations for our model which is to be used in the Bayesian Inference process. <code>priors</code> represent the  choice of prior distributions for the parameters to be determined, passed as an array of <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a> distributions. <code>t</code> is the array of time points. <code>transformations</code>  is an array of <a href="https://github.com/tpapp/ContinuousTransformations.jl">Tranformations</a> imposed for constraining the  parameter values to specific domains. <code>initial</code> values for the parameters can be passed, if not passed the means of the  <code>priors</code> are used. <code>Ïµ</code> can be used as a kwarg to pass the initial step size for the NUTS algorithm.      </p><h3 id="abc_inference"><a class="docs-heading-anchor" href="#abc_inference">abc_inference</a><a id="abc_inference-1"></a><a class="docs-heading-anchor-permalink" href="#abc_inference" title="Permalink"></a></h3><pre><code class="language-julia">abc_inference(prob::DEProblem, alg, t, data, priors; Ïµ=0.001,
     distancefunction = euclidean, ABCalgorithm = ABCSMC, progress = false,
     num_samples = 500, maxiterations = 10^5, kwargs...)</code></pre><p><code>abc_inference</code> uses <a href="https://github.com/marcjwilliams1/ApproxBayes.jl">ApproxBayes.jl</a> which uses Approximate Bayesian Computation (ABC) to perform its parameter inference. <code>prob</code> can be any <code>DEProblem</code> with a corresponding <code>alg</code> choice. <code>t</code> is the array of time points and <code>data[:,i]</code> is the set of observations for the differential equation system at time point <code>t[i]</code> (or higher dimensional). <code>priors</code> is an array of prior distributions for each parameter, specified via a <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a> type. <code>num_samples</code> is the number of posterior samples. <code>Ïµ</code> is the target distance between the data and simulated data. <code>distancefunction</code> is a distance metric specified from the <a href="https://github.com/JuliaStats/Distances.jl">Distances.jl</a> package, the default is <code>euclidean</code>. <code>ABCalgorithm</code> is the ABC algorithm to use, options are <code>ABCSMC</code> or <code>ABCRejection</code> from <a href="https://github.com/marcjwilliams1/ApproxBayes.jl">ApproxBayes.jl</a>, the default is the former which is more efficient. <code>maxiterations</code> is the maximum number of iterations before the algorithm terminates. The extra <code>kwargs</code> are given to the internal differential equation solver.</p><h2 id="Optimization-Based-ODE-Inference-Examples"><a class="docs-heading-anchor" href="#Optimization-Based-ODE-Inference-Examples">Optimization-Based ODE Inference Examples</a><a id="Optimization-Based-ODE-Inference-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-Based-ODE-Inference-Examples" title="Permalink"></a></h2><h3 id="Simple-Local-Optimization"><a class="docs-heading-anchor" href="#Simple-Local-Optimization">Simple Local Optimization</a><a id="Simple-Local-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Simple-Local-Optimization" title="Permalink"></a></h3><p>We choose to optimize the parameters on the Lotka-Volterra equation. We do so by defining the function as a function with parameters:</p><pre><code class="language-julia">function f(du,u,p,t)
  du[1] = dx = p[1]*u[1] - u[1]*u[2]
  du[2] = dy = -3*u[2] + u[1]*u[2]
end

u0 = [1.0;1.0]
tspan = (0.0,10.0)
p = [1.5]
prob = ODEProblem(f,u0,tspan,p)</code></pre><p>We create data using the numerical result with <code>a=1.5</code>:</p><pre><code class="language-julia">sol = solve(prob,Tsit5())
t = collect(range(0,stop=10,length=200))
using RecursiveArrayTools # for VectorOfArray
randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
data = convert(Array,randomized)</code></pre><p>Here we used <code>VectorOfArray</code> from <a href="https://github.com/ChrisRackauckas/RecursiveArrayTools.jl">RecursiveArrayTools.jl</a> to turn the result of an ODE into a matrix.</p><p>If we plot the solution with the parameter at <code>a=1.42</code>, we get the following:</p><p><img alt="Parameter Estimation Not Fit" src="../../assets/paramest_notfit.png"/></p><p>Notice that after one period this solution begins to drift very far off: this problem is sensitive to the choice of <code>a</code>.</p><p>To build the objective function for Optim.jl, we simply call the <code>build_loss_objective</code> function:</p><pre><code class="language-julia">cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data),
                                     maxiters=10000,verbose=false)</code></pre><p>This objective function internally is calling the ODE solver to get solutions to test against the data. The keyword arguments are passed directly to the solver. Note that we set <code>maxiters</code> in a way that causes the differential equation solvers to error more quickly when in bad regions of the parameter space, speeding up the process. If the integrator stops early (due to divergence), then those parameters are given an infinite loss, and thus this is a quick way to avoid bad parameters. We set <code>verbose=false</code> because this divergence can get noisy.</p><p>Before optimizing, let's visualize our cost function by plotting it for a range of parameter values:</p><pre><code class="language-julia">vals = 0.0:0.1:10.0
using Plots; plotly()
plot(vals,[cost_function(i) for i in vals],yscale=:log10,
     xaxis = "Parameter", yaxis = "Cost", title = "1-Parameter Cost Function",
     lw = 3)</code></pre><p><img alt="1 Parameter Likelihood" src="../../assets/1paramcost.png"/></p><p>Here we see that there is a very well-defined minimum in our cost function at the real parameter (because this is where the solution almost exactly fits the dataset).</p><p>Now this cost function can be used with Optim.jl in order to get the parameters. For example, we can use Brent's algorithm to search for the best solution on the interval <code>[0,10]</code> by:</p><pre><code class="language-julia">using Optim
result = optimize(cost_function, 0.0, 10.0)</code></pre><p>This returns <code>result.minimizer[1]==1.5</code> as the best parameter to match the data. When we plot the fitted equation on the data, we receive the following:</p><p><img alt="Parameter Estimation Fit" src="../../assets/paramest_fit.png"/></p><p>Thus we see that after fitting, the lines match up with the generated data and receive the right parameter value.</p><p>We can also use the multivariate optimization functions. For example, we can use the <code>BFGS</code> algorithm to optimize the parameter starting at <code>a=1.42</code> using:</p><pre><code class="language-julia">result = optimize(cost_function, [1.42], BFGS())</code></pre><p>Note that some of the algorithms may be sensitive to the initial condition. For more details on using Optim.jl, see the <a href="https://julianlsolvers.github.io/Optim.jl/stable/">documentation for Optim.jl</a>. We can improve our solution by noting that the Lotka-Volterra equation requires that the parameters are positive. Thus <a href="https://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/#box-constrained-optimization">following the Optim.jl documentation</a> we can add box constraints to ensure the optimizer only checks between 0.0 and 3.0 which improves the efficiency of our algorithm:</p><pre><code class="language-julia">lower = [0.0]
upper = [3.0]
result = optimize(cost_function, lower, upper, [1.42], Fminbox(BFGS()))</code></pre><p>Lastly, we can use the same tools to estimate multiple parameters simultaneously. Let's use the Lotka-Volterra equation with all parameters free:</p><pre><code class="language-julia">function f2(du,u,p,t)
  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]
  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]
end

u0 = [1.0;1.0]
tspan = (0.0,10.0)
p = [1.5,1.0,3.0,1.0]
prob = ODEProblem(f2,u0,tspan,p)</code></pre><p>We can build an objective function and solve the multiple parameter version just as before:</p><pre><code class="language-julia">cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data),
                                      maxiters=10000,verbose=false)
result_bfgs = Optim.optimize(cost_function, [1.3,0.8,2.8,1.2], Optim.BFGS())</code></pre><p>We can also use First-Differences in L2Loss by passing the kwarg <code>differ_weight</code> which decides the contribution of the differencing loss to the total loss.</p><pre><code class="language-julia">cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data,differ_weight=0.3,data_weight=0.7),
                                      maxiters=10000,verbose=false)
result_bfgs = Optim.optimize(cost_function, [1.3,0.8,2.8,1.2], Optim.BFGS())</code></pre><p>To solve it using LeastSquaresOptim.jl, we use the <code>build_lsoptim_objective</code> function:</p><pre><code class="language-julia">cost_function = build_lsoptim_objective(prob1,t,data,Tsit5())</code></pre><p>The result is a cost function which can be used with LeastSquaresOptim. For more details, consult the <a href="https://github.com/matthieugomez/LeastSquaresOptim.jl">documentation for LeastSquaresOptim.jl</a>:</p><pre><code class="language-julia">x = [1.3,0.8,2.8,1.2]
res = optimize!(LeastSquaresProblem(x = x, f! = cost_function,
                output_length = length(t)*length(prob.u0)),
                LeastSquaresOptim.Dogleg(),LeastSquaresOptim.LSMR())</code></pre><p>We can see the results are:</p><pre><code class="language-julia">println(res.minimizer)

Results of Optimization Algorithm
 * Algorithm: Dogleg
 * Minimizer: [1.4995074428834114,0.9996531871795851,3.001556360700904,1.0006272074128821]
 * Sum of squares at Minimum: 0.035730
 * Iterations: 63
 * Convergence: true
 * |x - x'| &lt; 1.0e-15: true
 * |f(x) - f(x')| / |f(x)| &lt; 1.0e-14: false
 * |g(x)| &lt; 1.0e-14: false
 * Function Calls: 64
 * Gradient Calls: 9
 * Multiplication Calls: 135</code></pre><p>and thus this algorithm was able to correctly identify all four parameters.</p><p>We can also use Multiple Shooting method by creating a <code>multiple_shooting_objective</code></p><pre><code class="language-julia">function ms_f(du,u,p,t)
  dx = p[1]*u[1] - p[2]*u[1]*u[2]
  dy = -3*u[2] + u[1]*u[2]
end
ms_u0 = [1.0;1.0]
tspan = (0.0,10.0)
ms_p = [1.5,1.0]
ms_prob = ODEProblem(ms_f,ms_u0,tspan,ms_p)
t = collect(range(0,stop=10,length=200))
data = Array(solve(ms_prob,Tsit5(),saveat=t,abstol=1e-12,reltol=1e-12))
bound = Tuple{Float64, Float64}[(0, 10),(0, 10),(0, 10),(0, 10),
                                (0, 10),(0, 10),(0, 10),(0, 10),
                                (0, 10),(0, 10),(0, 10),(0, 10),
                                (0, 10),(0, 10),(0, 10),(0, 10),(0, 10),(0, 10)]


ms_obj = multiple_shooting_objective(ms_prob,Tsit5(),L2Loss(t,data);discontinuity_weight=1.0,abstol=1e-12,reltol=1e-12)</code></pre><p>This creates the objective function that can be passed to an optimizer from which we can then get the parameter values and the initial values of the short time periods keeping in mind the indexing.</p><pre><code class="language-julia">result = bboptimize(ms_obj;SearchRange = bound, MaxSteps = 21e3)
result.archive_output.best_candidate[end-1:end]</code></pre><p>Giving us the results as</p><pre><code class="language-julia">Starting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},BlackBoxOptim.RadiusLimitedSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound{BlackBoxOptim.RangePerDimSearchSpace}}

Optimization stopped after 21001 steps and 136.60030698776245 seconds
Termination reason: Max number of steps (21000) reached
Steps per second = 153.7405036862868
Function evals per second = 154.43596332393247
Improvements/step = 0.17552380952380953
Total function evaluations = 21096


Best candidate found: [0.997396, 1.04664, 3.77834, 0.275823, 2.14966, 4.33106, 1.43777, 0.468442, 6.22221, 0.673358, 0.970036, 2.05182, 2.4216, 0.274394, 5.64131, 3.38132, 1.52826, 1.01721]

Fitness: 0.126884213

Out[4]:2-element Array{Float64,1}:
        1.52826
        1.01721</code></pre><p>Here as our model had 2 parameters, we look at the last two indexes of <code>result</code> to get our parameter values and the rest of the values are the initial values of the shorter timespans as described in the reference section.</p><p>The objective function for Two Stage method can be created and passed to an optimizer as</p><pre><code class="language-julia">two_stage_obj = two_stage_method(ms_prob,t,data)
result = Optim.optimize(two_stage_obj, [1.3,0.8,2.8,1.2], Optim.BFGS()
)
Results of Optimization Algorithm
 * Algorithm: BFGS
 * Starting Point: [1.3,0.8,2.8,1.2]
 * Minimizer: [1.5035938533664717,0.9925731153746833, ...]
 * Minimum: 1.513400e+00
 * Iterations: 9
 * Convergence: true
   * |x - x'| â¤ 0.0e+00: false
     |x - x'| = 4.58e-10
   * |f(x) - f(x')| â¤ 0.0e+00 |f(x)|: false
     |f(x) - f(x')| = 5.87e-16 |f(x)|
   * |g(x)| â¤ 1.0e-08: true
     |g(x)| = 7.32e-11
   * Stopped by an increasing objective: false
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 31
 * Gradient Calls: 31</code></pre><p>The default kernel used in the method is <code>Epanechnikov</code> others that are available are <code>Uniform</code>,  <code>Triangular</code>, <code>Quartic</code>, <code>Triweight</code>, <code>Tricube</code>, <code>Gaussian</code>, <code>Cosine</code>, <code>Logistic</code> and <code>Sigmoid</code>, this can be passed by the <code>kernel</code> keyword argument. <code>loss_func</code> keyword argument can be used to pass the loss function (cost function) you want  to use and <code>mpg_autodiff</code> enables Auto Differentiation.</p><h3 id="More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers"><a class="docs-heading-anchor" href="#More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers">More Algorithms (Global Optimization) via MathProgBase Solvers</a><a id="More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers-1"></a><a class="docs-heading-anchor-permalink" href="#More-Algorithms-(Global-Optimization)-via-MathProgBase-Solvers" title="Permalink"></a></h3><p>The <code>build_loss_objective</code> function builds an objective function which is able to be used with MathProgBase-associated solvers. This includes packages like IPOPT, NLopt, MOSEK, etc. Building off of the previous example, we can build a cost function for the single parameter optimization problem like:</p><pre><code class="language-julia">function f(du,u,p,t)
  dx = p[1]*u[1] - u[1]*u[2]
  dy = -3*u[2] + u[1]*u[2]
end

u0 = [1.0;1.0]
tspan = (0.0,10.0)
p = [1.5]
prob = ODEProblem(f,u0,tspan,p)
sol = solve(prob,Tsit5())

t = collect(range(0,stop=10,length=200))
randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
data = convert(Array,randomized)

obj = build_loss_objective(prob,Tsit5(),L2Loss(t,data),maxiters=10000)</code></pre><p>We can now use this <code>obj</code> as the objective function with MathProgBase solvers. For our example, we will use NLopt. To use the local derivative-free Constrained Optimization BY Linear Approximations algorithm, we can simply do:</p><pre><code class="language-julia">using NLopt
opt = Opt(:LN_COBYLA, 1)
min_objective!(opt, obj)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>This finds a minimum at <code>[1.49997]</code>. For a modified evolutionary algorithm, we can use:</p><pre><code class="language-julia">opt = Opt(:GN_ESCH, 1)
min_objective!(opt, obj)
lower_bounds!(opt,[0.0])
upper_bounds!(opt,[5.0])
xtol_rel!(opt,1e-3)
maxeval!(opt, 100000)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>We can even use things like the Improved Stochastic Ranking Evolution Strategy (and add constraints if needed). This is done via:</p><pre><code class="language-julia">opt = Opt(:GN_ISRES, 1)
min_objective!(opt, obj.cost_function2)
lower_bounds!(opt,[-1.0])
upper_bounds!(opt,[5.0])
xtol_rel!(opt,1e-3)
maxeval!(opt, 100000)
(minf,minx,ret) = NLopt.optimize(opt,[0.2])</code></pre><p>which is very robust to the initial condition. The fastest result comes from the following:</p><pre><code class="language-julia">using NLopt
opt = Opt(:LN_BOBYQA, 1)
min_objective!(opt, obj)
(minf,minx,ret) = NLopt.optimize(opt,[1.3])</code></pre><p>For more information, see the NLopt documentation for more details. And give IPOPT or MOSEK a try!</p><h3 id="Using-JuMP-with-DiffEqParamEstim"><a class="docs-heading-anchor" href="#Using-JuMP-with-DiffEqParamEstim">Using JuMP with DiffEqParamEstim</a><a id="Using-JuMP-with-DiffEqParamEstim-1"></a><a class="docs-heading-anchor-permalink" href="#Using-JuMP-with-DiffEqParamEstim" title="Permalink"></a></h3><p><a href="https://github.com/JuliaOpt/JuMP.jl">JuMP</a> is a domain-specific modeling language for mathematical optimization embedded in Julia.</p><pre><code class="language-julia">using OrdinaryDiffEq, DiffEqParamEstim, JuMP, NLopt, Plots</code></pre><p>Let's define the Lorenz equation to use as our example</p><pre><code class="language-julia">function g(du,u,p,t)
  Ï,Ï,Î² = p
  x,y,z = u
  du[1] = dx = Ï*(y-x)
  du[2] = dy = x*(Ï-z) - y
  du[3] = dz = x*y - Î²*z
end</code></pre><p>Let's get a solution of the system with parameter values <code>Ï=10.0</code><code>Ï=28.0</code><code>Î²=8/3</code> to use as our data. We define some convenience functions <code>model_ode</code> (to create an <code>ODEProblem</code>) and <code>solve_model</code>(to obtain solution of the <code>ODEProblem</code>) to use in a custom objective function later.</p><pre><code class="language-julia">u0 = [1.0;0.0;0.0]
t = 0.0:0.01:1.0
tspan = (0.0,1.0)
model_ode(p_) = ODEProblem(g, u0, tspan,p_)
solve_model(mp_) = OrdinaryDiffEq.solve(model_ode(mp_), Tsit5(),saveat=0.01)
mock_data = Array(solve_model([10.0,28.0,8/3]))</code></pre><p>Now we define a custom objective function to pass for optimization to JuMP using the <code>build_loss_objective</code> described above provided by DiffEqParamEstim that defines an objective function for the parameter estimation problem.</p><pre><code class="language-julia">loss_objective(mp_, dat) = build_loss_objective(model_ode(mp_), Tsit5(), L2Loss(t,dat))</code></pre><p>We create a JuMP model, variables, set the objective function and the choice of optimization algorithm to be used in the JuMP syntax. You can read more about this in JuMP's <a href="http://www.juliaopt.org/JuMP.jl/0.18/index.html">documentation</a>.</p><pre><code class="language-julia">juobj(args...) = loss_objective(args, mock_data)(args)
jumodel = Model()
JuMP.register(jumodel, :juobj, 3, juobj, autodiff=true)
@variables jumodel begin
    Ï,(start=8)
    Ï,(start=25.0)
    Î²,(start=10/3)
end
@NLobjective(jumodel, Min, juobj(Ï, Ï, Î²))
setsolver(jumodel, NLoptSolver(algorithm=:LD_MMA))</code></pre><p>Let's call the optimizer to obtain the fitted parameter values.</p><pre><code class="language-julia">sol = JuMP.solve(jumodel)
best_mp = getvalue.(getindex.((jumodel,), Symbol.(jumodel.colNames)))</code></pre><p>Let's compare the solution at the obtained parameter values and our data.</p><pre><code class="language-julia">sol = OrdinaryDiffEq.solve(best_mp |&gt; model_ode, Tsit5())
plot(getindex.(sol.(t),1))
scatter!(mock_data, markersize=2)</code></pre><p><img alt="jumpestimationplot" src="../../assets/jumpestimationplot.png"/></p><h3 id="Generalized-Likelihood-Example"><a class="docs-heading-anchor" href="#Generalized-Likelihood-Example">Generalized Likelihood Example</a><a id="Generalized-Likelihood-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Generalized-Likelihood-Example" title="Permalink"></a></h3><p>In this example we will demo the likelihood-based approach to parameter fitting. First let's generate a dataset to fit. We will re-use the Lotka-Volterra equation but in this case fit just two parameters.</p><pre><code class="language-julia">f1 = function (du,u,p,t)
  du[1] = p[1] * u[1] - p[2] * u[1]*u[2]
  du[2] = -3.0 * u[2] + u[1]*u[2]
end
p = [1.5,1.0]
u0 = [1.0;1.0]
tspan = (0.0,10.0)
prob1 = ODEProblem(f1,u0,tspan,p)
sol = solve(prob1,Tsit5())</code></pre><p>This is a function with two parameters, <code>[1.5,1.0]</code> which generates the same ODE solution as before. This time, let's generate 100 datasets where at each point adds a little bit of randomness:</p><pre><code class="language-julia">using RecursiveArrayTools # for VectorOfArray
t = collect(range(0,stop=10,length=200))
function generate_data(sol,t)
  randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
  data = convert(Array,randomized)
end
aggregate_data = convert(Array,VectorOfArray([generate_data(sol,t) for i in 1:100]))</code></pre><p>here with <code>t</code> we measure the solution at 200 evenly spaced points. Thus <code>aggregate_data</code> is a 2x200x100 matrix where <code>aggregate_data[i,j,k]</code> is the <code>i</code>th component at time <code>j</code> of the <code>k</code>th dataset. What we first want to do is get a matrix of distributions where <code>distributions[i,j]</code> is the likelihood of component <code>i</code> at take <code>j</code>. We can do this via <code>fit_mle</code> on a chosen distributional form. For simplicity we choose the <code>Normal</code> distribution. <code>aggregate_data[i,j,:]</code> is the array of points at the given component and time, and thus we find the distribution parameters which fits best at each time point via:</p><pre><code class="language-julia">using Distributions
distributions = [fit_mle(Normal,aggregate_data[i,j,:]) for i in 1:2, j in 1:200]</code></pre><p>Notice for example that we have:</p><pre><code class="language-julia">julia&gt; distributions[1,1]
Distributions.Normal{Float64}(Î¼=1.0022440583676806, Ï=0.009851964521952437)</code></pre><p>that is, it fit the distribution to have its mean just about where our original solution was and the variance is about how much noise we added to the dataset. This this is a good check to see that the distributions we are trying to fit our parameters to makes sense.</p><p>Note that in this case the <code>Normal</code> distribution was a good choice, and in many cases it's a nice go-to choice, but one should experiment with other choices of distributions as well. For example, a <code>TDist</code> can be an interesting way to incorporate robustness to outliers since low degrees of free T-distributions act like Normal distributions but with longer tails (though <code>fit_mle</code> does not work with a T-distribution, you can get the means/variances and build appropriate distribution objects yourself).</p><p>Once we have the matrix of distributions, we can build the objective function corresponding to that distribution fit:</p><pre><code class="language-julia">using DiffEqParamEstim
obj = build_loss_objective(prob1,Tsit5(),LogLikeLoss(t,distributions),
                                     maxiters=10000,verbose=false)</code></pre><p>First let's use the objective function to plot the likelihood landscape:</p><pre><code class="language-julia">using Plots; plotly()
prange = 0.5:0.1:5.0
heatmap(prange,prange,[obj([j,i]) for i in prange, j in prange],
        yscale=:log10,xlabel="Parameter 1",ylabel="Parameter 2",
        title="Likelihood Landscape")</code></pre><p><img alt="2 Parameter Likelihood" src="../../assets/2paramlike.png"/></p><p>Recall that this is the negative loglikelihood and thus the minimum is the maximum of the likelihood. There is a clear valley where the first parameter is 1.5, while the second parameter's likelihood is more muddled. By taking a one-dimensional slice:</p><pre><code class="language-julia">plot(prange,[obj([1.5,i]) for i in prange],lw=3,
     title="Parameter 2 Likelihood (Parameter 1 = 1.5)",
     xlabel = "Parameter 2", ylabel = "Objective Function Value")</code></pre><p><img alt="1 Parameter Likelihood" src="../../assets/1paramlike.png"/></p><p>we can see that there's still a clear minimum at the true value. Thus we will use the global optimizers from BlackBoxOptim.jl to find the values. We set our search range to be from <code>0.5</code> to <code>5.0</code> for both of the parameters and let it optimize:</p><pre><code class="language-julia">using BlackBoxOptim
bound1 = Tuple{Float64, Float64}[(0.5, 5),(0.5, 5)]
result = bboptimize(obj;SearchRange = bound1, MaxSteps = 11e3)

Starting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},B
lackBoxOptim.RadiusLimitedSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound
{BlackBoxOptim.RangePerDimSearchSpace}}
0.00 secs, 0 evals, 0 steps
0.50 secs, 1972 evals, 1865 steps, improv/step: 0.266 (last = 0.2665), fitness=-737.311433781
1.00 secs, 3859 evals, 3753 steps, improv/step: 0.279 (last = 0.2913), fitness=-739.658421879
1.50 secs, 5904 evals, 5799 steps, improv/step: 0.280 (last = 0.2830), fitness=-739.658433715
2.00 secs, 7916 evals, 7811 steps, improv/step: 0.225 (last = 0.0646), fitness=-739.658433715
2.50 secs, 9966 evals, 9861 steps, improv/step: 0.183 (last = 0.0220), fitness=-739.658433715

Optimization stopped after 11001 steps and 2.7839999198913574 seconds
Termination reason: Max number of steps (11000) reached
Steps per second = 3951.50873439296
Function evals per second = 3989.2242527195904
Improvements/step = 0.165
Total function evaluations = 11106


Best candidate found: [1.50001, 1.00001]

Fitness: -739.658433715</code></pre><p>This shows that it found the true parameters as the best fit to the likelihood.</p><h2 id="Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles"><a class="docs-heading-anchor" href="#Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles">Parameter Estimation for Stochastic Differential Equations and Ensembles</a><a id="Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles" title="Permalink"></a></h2><p>We can use any <code>DEProblem</code>, which not only includes <code>DAEProblem</code> and <code>DDEProblem</code>s, but also stochastic problems. In this case, let's use the generalized maximum likelihood to fit the parameters of an SDE's ensemble evaluation.</p><p>Let's use the same Lotka-Volterra equation as before, but this time add noise:</p><pre><code class="language-julia">pf_func = function (du,u,p,t)
  du[1] = p[1] * u[1] - p[2] * u[1]*u[2]
  du[2] = -3 * u[2] + u[1]*u[2]
end

u0 = [1.0;1.0]
tspan = (0.0,10.0)
p = [1.5,1.0]
pg_func = function (du,u,p,t)
  du[1] = 1e-6u[1]
  du[2] = 1e-6u[2]
end
prob = SDEProblem(pf_func,pg_func,u0,tspan,p)
sol = solve(prob,SRIW1())</code></pre><p>Now lets generate a dataset from 10,000 solutions of the SDE</p><pre><code class="language-julia">using RecursiveArrayTools # for VectorOfArray
t = collect(range(0, stop=10, length=200))
function generate_data(t)
  sol = solve(prob,SRIW1())
  randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
  data = convert(Array,randomized)
end
aggregate_data = convert(Array,VectorOfArray([generate_data(t) for i in 1:10000]))</code></pre><p>Now let's estimate the parameters. Instead of using single runs from the SDE, we will use a <code>EnsembleProblem</code>. This means that it will solve the SDE <code>N</code> times to come up with an approximate probability distribution at each time point and use that in the likelihood estimate.</p><pre><code class="language-julia">monte_prob = EnsembleProblem(prob)</code></pre><p>We use Optim.jl for optimization below</p><pre><code class="language-julia">obj = build_loss_objective(monte_prob,SOSRI(),L2Loss(t,aggregate_data),
                                     maxiters=10000,verbose=false,num_monte = 1000,
                                     parallel_type = :threads)
result = Optim.optimize(obj, [1.0,0.5], Optim.BFGS())</code></pre><p>Parameter Estimation in case of SDE's with a regular <code>L2Loss</code> can have poor accuracy due to only fitting against the mean properties as mentioned in <a href="http://docs.juliadiffeq.org/dev/analysis/parameter_estimation/#First-differencing-1">First Differencing</a>.</p><pre><code class="language-julia">Results of Optimization Algorithm
 * Algorithm: BFGS
 * Starting Point: [1.0,0.5]
 * Minimizer: [6.070728870478734,5.113357737345448]
 * Minimum: 1.700440e+03
 * Iterations: 14
 * Convergence: false
   * |x - x'| â¤ 0.0e+00: false
     |x - x'| = 1.00e-03
   * |f(x) - f(x')| â¤ 0.0e+00 |f(x)|: false
     |f(x) - f(x')| = 1.81e-07 |f(x)|
   * |g(x)| â¤ 1.0e-08: false
     |g(x)| = 2.34e+00
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 61
 * Gradient Calls: 61</code></pre><p>Instead when we use <code>L2Loss</code> with first differencing enabled we get much more accurate estimates.</p><pre><code class="language-julia"> obj = build_loss_objective(monte_prob,SRIW1(),L2Loss(t,data,differ_weight=1.0,data_weight=0.5),maxiters=1000,
                                  verbose=false,verbose_opt=false,verbose_steps=1,num_monte=50)
result = Optim.optimize(obj, [1.0,0.5], Optim.BFGS())
Results of Optimization Algorithm
 * Algorithm: BFGS
 * Starting Point: [1.0,0.5]
 * Minimizer: [1.5010687426045128,1.0023453619050238]
 * Minimum: 1.166650e-01
 * Iterations: 16
 * Convergence: false
   * |x - x'| â¤ 0.0e+00: false
     |x - x'| = 6.84e-09
   * |f(x) - f(x')| â¤ 0.0e+00 |f(x)|: false
     |f(x) - f(x')| = 5.85e-06 |f(x)|
   * |g(x)| â¤ 1.0e-08: false
     |g(x)| = 1.81e-01
   * Stopped by an increasing objective: true
   * Reached Maximum Number of Iterations: false
 * Objective Calls: 118
 * Gradient Calls: 118</code></pre><p>Here we see that we successfully recovered the drift parameter, and got close to the original noise parameter after searching a two orders of magnitude range.</p><h2 id="Bayesian-Inference-Examples"><a class="docs-heading-anchor" href="#Bayesian-Inference-Examples">Bayesian Inference Examples</a><a id="Bayesian-Inference-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Inference-Examples" title="Permalink"></a></h2><h3 id="Stan"><a class="docs-heading-anchor" href="#Stan">Stan</a><a id="Stan-1"></a><a class="docs-heading-anchor-permalink" href="#Stan" title="Permalink"></a></h3><p>Like in the previous examples, we setup the Lotka-Volterra system and generate data.</p><pre><code class="language-julia">f1 = @ode_def begin
  dx = a*x - b*x*y
  dy = -c*y + d*x*y
end a b c d
p = [1.5,1.0,3.0,1.0]
u0 = [1.0,1.0]
tspan = (0.0,10.0)
prob1 = ODEProblem(f1,u0,tspan,p)
sol = solve(prob1,Tsit5())
t = collect(range(1,stop=10,length=10))
randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])
data = convert(Array,randomized)</code></pre><p>Here we now give Stan an array of prior distributions for our parameters. Since the parameters of our differential equation must be positive, we utilize truncated Normal distributions to make sure that is satisfied in the result:</p><pre><code class="language-julia">priors = [Truncated(Normal(1.5,0.1),0,2),Truncated(Normal(1.0,0.1),0,1.5),
          Truncated(Normal(3.0,0.1),0,4),Truncated(Normal(1.0,0.1),0,2)]</code></pre><p>We then give these to the inference function.</p><pre><code class="language-julia">bayesian_result = stan_inference(prob1,t,data,priors;
                                 num_samples=100,num_warmup=500,
                                 vars = (StanODEData(),InverseGamma(4,1)))</code></pre><p><code>InverseGamma(4,1)</code> is our starting estimation for the variance hyperparameter of the default <code>Normal</code> distribution. The result is a <a href="http://mambajl.readthedocs.io/en/dev/intro.html">Mamba.jl</a> chain object. We can pull out the parameter values via:</p><pre><code class="language-julia">theta1 = bayesian_result.chain_results[:,["theta.1"],:]
theta2 = bayesian_result.chain_results[:,["theta.2"],:]
theta3 = bayesian_result.chain_results[:,["theta.3"],:]
theta4 = bayesian_result.chain_results[:,["theta.4"],:]</code></pre><p>From these chains we can get our estimate for the parameters via:</p><pre><code class="language-julia">mean(theta1.value[:,:,1])</code></pre><p>We can get more of a description via:</p><pre><code class="language-julia">Mamba.describe(bayesian_result.chain_results)

# Result

Iterations = 1:100
Thinning interval = 1
Chains = 1,2,3,4
Samples per chain = 100

Empirical Posterior Estimates:
                  Mean         SD        Naive SE        MCSE         ESS    
         lp__ -6.15472697 1.657551334 0.08287756670 0.18425029767  80.9314979
accept_stat__  0.90165904 0.125913744 0.00629568721 0.02781181930  20.4968668
   stepsize__  0.68014975 0.112183047 0.00560915237 0.06468790087   3.0075188
  treedepth__  2.68750000 0.524911975 0.02624559875 0.10711170182  24.0159141
 n_leapfrog__  6.77000000 4.121841086 0.20609205428 0.18645821695 100.0000000
  divergent__  0.00000000 0.000000000 0.00000000000 0.00000000000         NaN
     energy__  9.12245750 2.518330231 0.12591651153 0.32894488320  58.6109941
     sigma1.1  0.57164997 0.128579363 0.00642896816 0.00444242658 100.0000000
     sigma1.2  0.58981422 0.131346442 0.00656732209 0.00397310122 100.0000000
       theta1  1.50237077 0.008234095 0.00041170473 0.00025803930 100.0000000
       theta2  0.99778276 0.009752574 0.00048762870 0.00009717115 100.0000000
       theta3  3.00087782 0.009619775 0.00048098873 0.00020301023 100.0000000
       theta4  0.99803569 0.008893244 0.00044466218 0.00040886528 100.0000000
      theta.1  1.50237077 0.008234095 0.00041170473 0.00025803930 100.0000000
      theta.2  0.99778276 0.009752574 0.00048762870 0.00009717115 100.0000000
      theta.3  3.00087782 0.009619775 0.00048098873 0.00020301023 100.0000000
      theta.4  0.99803569 0.008893244 0.00044466218 0.00040886528 100.0000000

Quantiles:
                  2.5%        25.0%      50.0%      75.0%       97.5%   
         lp__ -10.11994750 -7.0569000 -5.8086150 -4.96936500 -3.81514375
accept_stat__   0.54808912  0.8624483  0.9472840  0.98695850  1.00000000
   stepsize__   0.57975100  0.5813920  0.6440120  0.74276975  0.85282400
  treedepth__   2.00000000  2.0000000  3.0000000  3.00000000  3.00000000
 n_leapfrog__   3.00000000  7.0000000  7.0000000  7.00000000 15.00000000
  divergent__   0.00000000  0.0000000  0.0000000  0.00000000  0.00000000
     energy__   5.54070300  7.2602200  8.7707000 10.74517500 14.91849500
     sigma1.1   0.38135240  0.4740865  0.5533195  0.64092575  0.89713635
     sigma1.2   0.39674703  0.4982615  0.5613655  0.66973025  0.88361407
       theta1   1.48728600  1.4967650  1.5022750  1.50805500  1.51931475
       theta2   0.97685115  0.9914630  0.9971435  1.00394250  1.01765575
       theta3   2.98354100  2.9937575  3.0001450  3.00819000  3.02065950
       theta4   0.97934128  0.9918495  0.9977415  1.00430750  1.01442975
      theta.1   1.48728600  1.4967650  1.5022750  1.50805500  1.51931475
      theta.2   0.97685115  0.9914630  0.9971435  1.00394250  1.01765575
      theta.3   2.98354100  2.9937575  3.0001450  3.00819000  3.02065950
      theta.4   0.97934128  0.9918495  0.9977415  1.00430750  1.01442975</code></pre><p>More extensive information about the distributions is given by the plots:</p><pre><code class="language-julia">plot_chain(bayesian_result)</code></pre><h3 id="Turing"><a class="docs-heading-anchor" href="#Turing">Turing</a><a id="Turing-1"></a><a class="docs-heading-anchor-permalink" href="#Turing" title="Permalink"></a></h3><p>This case we will build off of the Stan example. Note that <code>turing_inference</code> does not require the use of the <code>@ode_def</code> macro like Stan does, but it will still work with macro-defined functions. Thus, using the same setup as before, we simply give the setup to:</p><pre><code class="language-julia">bayesian_result = turing_inference(prob,Tsit5(),t,data,priors;num_samples=500)</code></pre><p>The chain for the <code>i</code>th parameter is then given by:</p><pre><code class="language-julia">bayesian_result[:theta1]</code></pre><p>Summary statistics can be also be accessed:</p><pre><code class="language-julia">Mamba.describe(bayesian_result)</code></pre><p>The chain can be analysed by the trace plots and other plots obtained by:</p><pre><code class="language-julia">plot_chain(bayesian_result)</code></pre><h3 id="DynamicHMC"><a class="docs-heading-anchor" href="#DynamicHMC">DynamicHMC</a><a id="DynamicHMC-1"></a><a class="docs-heading-anchor-permalink" href="#DynamicHMC" title="Permalink"></a></h3><p>We can use <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a> as the backend for sampling with the <code>dynamic_inference</code> function. It supports any <code>DEProblem</code>, <code>priors</code> can be passed as an array of <a href="https://juliastats.github.io/Distributions.jl/dev/">Distributions.jl</a> distributions, passing <code>initial</code> values is optional and in case where the user has a firm understanding of the domain the parameter values will lie in, <code>transformations</code> can be used to pass an array of constraints for the parameters as an array of <a href="https://github.com/tpapp/ContinuousTransformations.jl">Transformations</a>.</p><pre><code class="language-julia">bayesian_result_hmc = dynamichmc_inference(prob1, Tsit5(), t, data, [Normal(1.5, 1)], [bridge(â, ââº, )])</code></pre><p>A tuple with summary statistics and the chain values is returned. The chain for the <code>i</code>th parameter is given by:</p><pre><code class="language-julia">bayesian_result_hmc[1][i]</code></pre><p>For accessing the various summary statistics:</p><pre><code class="language-julia">DynamicHMC.NUTS_statistics(bayesian_result_dynamic[2])</code></pre><p>Some details about the NUTS sampler can be obtained from:</p><pre><code class="language-julia">bayesian_result_dynamic[3]</code></pre><p>In case of <code>dynamic_inference</code> the trace plots for the <code>i</code>th parameter can be obtained by:</p><pre><code class="language-julia">plot(bayesian_result_hmc[1][i])</code></pre><p>For a better idea of the summary statistics and plotting you can take a look at the <a href="https://github.com/JuliaDiffEq/DiffEqBenchmarks.jl">benchmarks</a></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../parameterized_functions/">Â« ParameterizedFunctions</a><a class="docs-footer-nextpage" href="../bifurcation/">Bifurcation Analysis Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label></p><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div><p></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 12 August 2020 03:39">Wednesday 12 August 2020</span>. Using Julia version 1.5.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></HTML>